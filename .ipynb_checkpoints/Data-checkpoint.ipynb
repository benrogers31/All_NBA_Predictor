{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup  # HTML data structure\n",
    "from urllib.request import urlopen as uReq  # Web client\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Building a Dictionary of Team Abbriviations and Full Names </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_names_dict = dict()\n",
    "\n",
    "page_url = \"https://en.wikipedia.org/wiki/Wikipedia:WikiProject_National_Basketball_Association/National_Basketball_Association_team_abbreviations\"\n",
    "\n",
    "#this downloads the webpage into an object\n",
    "uClient = uReq(page_url)\n",
    "page_soup = soup(uClient.read(), \"html.parser\")\n",
    "uClient.close()\n",
    "\n",
    "team_containers = page_soup.findAll(\"tr\")\n",
    "\n",
    "#setting the dicitonary of team names with keys as their abbrivations on basketball reference\n",
    "for row in team_containers[1:]:\n",
    "    \n",
    "    names = row.findAll(\"td\")\n",
    "    \n",
    "    full_name = names[0].text.replace(\"\\n\",\"\")\n",
    "    abr = names[1].text.replace(\"\\n\",\"\")\n",
    "    \n",
    "    team_names_dict[full_name] = abr \n",
    "\n",
    "#Need to manually insert older teams    \n",
    "team_names_dict['SEA'] = 'Seattle SuperSonics'\n",
    "team_names_dict['PHO'] =  'Phoenix Suns'\n",
    "team_names_dict['NJN'] = 'New Jersey Nets'\n",
    "team_names_dict['KCK']= 'Kansas City Kings'\n",
    "team_names_dict['WSB']= 'Washington Bullets'\n",
    "team_names_dict['SDC']='San Diego Clippers'\n",
    "team_names_dict['CHH']='Charlotte Hornets'\n",
    "team_names_dict['NOH']='New Orleans Hornets'\n",
    "team_names_dict['BRK']='Brooklyn Nets'\n",
    "#wtf espn \n",
    "team_names_dict['LAC']= 'LA Clippers'\n",
    "team_names_dict['CHO']= 'Charlotte Hornets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Getting Advanced Stats for each Season </h2> \n",
    "<p> We already have the counting stats from past seasons from a previous project </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Advanced_df = pd.DataFrame()\n",
    "\n",
    "for year in range(2020,2021):\n",
    "    \n",
    "    #Here we enter the URL we are trying to web scrape from \n",
    "    page_url = \"https://www.basketball-reference.com/leagues/NBA_\"+str(year)+\"_advanced.html\"\n",
    "\n",
    "    #this basically downloads the webpage into an object\n",
    "    uClient = uReq(page_url)\n",
    "    # parses html into a soup data structure to traverse html\n",
    "    # as if it were a json data type.\n",
    "    page_soup_advanced_stats  = soup(uClient.read(), \"html.parser\")\n",
    "    uClient.close()\n",
    "\n",
    "    #getting headers\n",
    "    player_table = page_soup_advanced_stats.findAll(\"table\", {\"id\": \"advanced_stats\"})\n",
    "    headers = player_table[0].find_all(\"thead\")[0].find_all(\"tr\")[0].find_all(\"th\")\n",
    "\n",
    "    columns = []\n",
    "    for col in headers[1:]: \n",
    "        columns.append(col.text)\n",
    "\n",
    "    #setting up our historical players df \n",
    "    Players_df = pd.DataFrame(columns = columns)\n",
    "\n",
    "    players = player_table[0].findAll(\"tbody\")[0].find_all(\"tr\")\n",
    "\n",
    "    num_of_fake_rows = 0\n",
    "\n",
    "    for i,player in enumerate(players):\n",
    "\n",
    "        #getting list of stats\n",
    "        stats = player.find_all(\"td\")\n",
    "\n",
    "        #storing stats in an array\n",
    "        stat_arr = []\n",
    "        for stat in stats: \n",
    "\n",
    "            stat_arr.append(stat.text)\n",
    "\n",
    "        # some rows are just for showing headers again and this skips over them\n",
    "        if not stat_arr:\n",
    "            num_of_fake_rows = num_of_fake_rows + 1\n",
    "            continue\n",
    "\n",
    "        #this stores all the stats to be taken into account when looking into MVP \n",
    "        player_df = dict(zip(Players_df.columns,stat_arr))\n",
    "\n",
    "        #getting the stats in the dataframe \n",
    "        Players_df = Players_df.append(player_df,ignore_index=True)\n",
    "\n",
    "    #exporting dataframe to a csv file \n",
    "    out_filename = \"csv_files/players_advanced_stats/\"+str(year)+\"_Players_Advanced.csv\"\n",
    "    Players_df.to_csv(path_or_buf = out_filename, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Now we are going to build our Past MVP Dataframes </h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_df = pd.DataFrame()\n",
    "\n",
    "for year in range(1980,2020):\n",
    "\n",
    "    ################# FIRST WE ARE GETTING TEAM STANDINGS ################# \n",
    "\n",
    "    #Now we get the stats for team record \n",
    "    page_url = \"https://www.espn.com/nba/standings/_/season/\"+str(year)+\"/group/league\"\n",
    "    uClient = uReq(page_url)\n",
    "    page_soup_team  = soup(uClient.read(), \"html.parser\")\n",
    "    uClient.close()\n",
    "\n",
    "    #Making a dictionary of team standings  \n",
    "    team_table = page_soup_team.find(\"tbody\",{\"class\":\"Table__TBODY\"}).findAll(\"tr\")\n",
    "\n",
    "    standings = dict()\n",
    "    for i,row in enumerate(team_table,start=1):\n",
    "        team_name = row.find(\"span\",{\"class\":\"hide-mobile\"}).text\n",
    "        standings[team_name] = i   \n",
    "\n",
    "    ################# NOW WE STORE WHO HAD MVP VOTES THIS SEASON #################     \n",
    "\n",
    "    #First we get the stats from former MVPs\n",
    "    page_url = \"https://www.basketball-reference.com/awards/awards_\"+str(year)+\".html\"\n",
    "    uClient = uReq(page_url)\n",
    "    page_soup_stats  = soup(uClient.read(), \"html.parser\")\n",
    "    uClient.close()\n",
    "\n",
    "    #getting the table with the MVP data\n",
    "    mvp_table = page_soup_stats.findAll(\"table\", {\"id\": \"mvp\"})\n",
    "\n",
    "\n",
    "    #get each row of players\n",
    "    player_votes = mvp_table[0].find_all(\"td\", {\"data-stat\":\"award_share\"})\n",
    "    player_names = mvp_table[0].find_all(\"td\", {\"data-stat\":\"player\"})\n",
    "\n",
    "\n",
    "    MVP_Votes = dict()\n",
    "    for i in range(len(player_votes)):\n",
    "        MVP_Votes[player_names[i].text] = player_votes[i].text \n",
    "        \n",
    "    ############# Here weare going to store who was. all nba this season ###########\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    ################ Now we check for if they were an all-star ###############\n",
    "\n",
    "    page_url = \"https://basketball.realgm.com/nba/allstar/game/rosters/\"+str(year)\n",
    "    uClient = uReq(page_url)\n",
    "    all_star_soup = soup(uClient.read(), \"html.parser\")\n",
    "    uClient.close()\n",
    "\n",
    "    allstars = all_star_soup.findAll(\"td\", {\"data-th\":\"Player\"})\n",
    "\n",
    "    allstar_arr = []\n",
    "    for a in allstars:\n",
    "        allstar_arr.append(a.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ################ Now we build the data_frame ##############\n",
    "\n",
    "    #loading dataframes\n",
    "    counting_stats_df = pd.read_csv('csv_files/player_counting_stats/player_stats_'+str(year)+'.csv')\n",
    "    advanced_stats_df = pd.read_csv(\"csv_files/players_advanced_stats/\"+str(year)+\"_Players_Advanced.csv\")\n",
    "\n",
    "\n",
    "    #fixing names so rows match\n",
    "    advanced_stats_df = advanced_stats_df.rename(columns={\"Player\":\"NAME\",\"Tm\":\"TEAM\",\"MP\":\"MPT\"})\n",
    "\n",
    "    #droppoing redundant rows\n",
    "    advanced_stats_df = advanced_stats_df.drop(['G','Pos'], 1)\n",
    "    advanced_stats_df.dropna(how='all', axis=1, inplace =True)\n",
    "\n",
    "    #merging the two dataframes\n",
    "    result = pd.merge(counting_stats_df,advanced_stats_df,on=['NAME'])\n",
    "    result.drop_duplicates(subset=['NAME','TEAM_x'], keep=\"first\", inplace=True)\n",
    "    result =result.drop(['TEAM_y'],axis=1).rename(columns={\"TEAM_x\":\"TEAM\"})\n",
    "    result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    Past_MVP_df = pd.DataFrame(columns = result.columns)\n",
    "\n",
    "    Past_MVP_df['ALLSTAR'] = None\n",
    "    Past_MVP_df['SHARE'] = None\n",
    "    Past_MVP_df['TEAM_STANDING'] = None\n",
    "\n",
    "\n",
    "    for i,player in result.iterrows():\n",
    "\n",
    "        ################# Adding ALLSTAR Column ##################\n",
    "        if player['NAME'].replace('*','') in allstar_arr:\n",
    "            player['ALLSTAR'] = 1\n",
    "        else:\n",
    "            player['ALLSTAR'] = 0\n",
    "\n",
    "        ##############  Adding MVP Share Column ###########\n",
    "        if player['NAME'].replace('*','') in MVP_Votes:\n",
    "            player['SHARE'] = MVP_Votes[player['NAME'].replace('*','')]\n",
    "        else:\n",
    "            player['SHARE'] = 0.000\n",
    "\n",
    "\n",
    "        ################ Adding Team standing column ############\n",
    "\n",
    "        team_abrv = player[\"TEAM\"].replace(' ','')\n",
    "\n",
    "        if team_abrv not in team_names_dict and team_abrv !=  'TOT' :\n",
    "            #print(team_abrv + \" not in dict\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            #if a player played on multiple teams in a year then its tough to take a look at their record so we \n",
    "            #just won't use them because there isn't that many\n",
    "            if team_abrv == 'TOT': \n",
    "\n",
    "                #since the team that a player is on now will likely be 2 rows below current player we take that player\n",
    "                curr_team_player = result.loc[i+2]\n",
    "\n",
    "                #Extracting the team ID\n",
    "\n",
    "                curr_team_id = curr_team_player['TEAM'].replace(' ','')\n",
    "\n",
    "                #this finds the team name for the player\n",
    "                team_name = team_names_dict[curr_team_id]\n",
    "                #Extract the standings for the current team \n",
    "                player['TEAM_STANDING'] = standings[team_name] \n",
    "            else:\n",
    "                #this finds the team name for the player\n",
    "                team_name = team_names_dict[team_abrv]\n",
    "                player['TEAM_STANDING'] = standings[team_name]\n",
    "\n",
    "        except:\n",
    "            #print( team_abrv+ \" ESPN doesn't have them in the standings this year\" )\n",
    "            continue\n",
    "\n",
    "        Past_MVP_df = Past_MVP_df.append(player,ignore_index=True)\n",
    "        \n",
    "    print(year)\n",
    "    Main_df = Main_df.append(Past_MVP_df,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_df\n",
    "\n",
    "#exporting dataframe to a csv file \n",
    "out_filename = \"csv_files/Past_Player_Data.csv\"\n",
    "Main_df.to_csv(path_or_buf = out_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Now we are going to get the data for current players </h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Current_df = pd.DataFrame()\n",
    "\n",
    "year = 2020\n",
    "\n",
    "################# FIRST WE ARE GETTING TEAM STANDINGS ################# \n",
    "\n",
    "#Now we get the stats for team record \n",
    "page_url = \"https://www.espn.com/nba/standings/_/season/\"+str(year)+\"/group/league\"\n",
    "uClient = uReq(page_url)\n",
    "page_soup_team  = soup(uClient.read(), \"html.parser\")\n",
    "uClient.close()\n",
    "\n",
    "#Making a dictionary of team standings  \n",
    "team_table = page_soup_team.find(\"tbody\",{\"class\":\"Table__TBODY\"}).findAll(\"tr\")\n",
    "\n",
    "standings = dict()\n",
    "for i,row in enumerate(team_table,start=1):\n",
    "    team_name = row.find(\"span\",{\"class\":\"hide-mobile\"}).text\n",
    "    standings[team_name] = i   \n",
    "\n",
    "################ Now we check for if they were an all-star ###############\n",
    "\n",
    "page_url = \"https://basketball.realgm.com/nba/allstar/game/rosters/\"+str(year)\n",
    "uClient = uReq(page_url)\n",
    "all_star_soup = soup(uClient.read(), \"html.parser\")\n",
    "uClient.close()\n",
    "\n",
    "allstars = all_star_soup.findAll(\"td\", {\"data-th\":\"Player\"})\n",
    "\n",
    "allstar_arr = []\n",
    "for a in allstars:\n",
    "    allstar_arr.append(a.text)\n",
    "\n",
    "    \n",
    "\n",
    "#loading dataframes\n",
    "counting_stats_df = pd.read_csv('csv_files/player_counting_stats/player_stats_'+str(year)+'.csv')\n",
    "advanced_stats_df = pd.read_csv(\"csv_files/players_advanced_stats/\"+str(year)+\"_Players_Advanced.csv\")\n",
    "\n",
    "\n",
    "#fixing names so rows match\n",
    "advanced_stats_df = advanced_stats_df.rename(columns={\"Player\":\"NAME\",\"Tm\":\"TEAM\",\"MP\":\"MPT\"})\n",
    "\n",
    "#droppoing redundant rows\n",
    "advanced_stats_df = advanced_stats_df.drop(['G','Pos'], 1)\n",
    "advanced_stats_df.dropna(how='all', axis=1, inplace =True)\n",
    "\n",
    "#merging the two dataframes\n",
    "result = pd.merge(counting_stats_df,advanced_stats_df,on=['NAME'])\n",
    "result.drop_duplicates(subset=['NAME','TEAM_x'], keep=\"first\", inplace=True)\n",
    "result =result.drop(['TEAM_y'],axis=1).rename(columns={\"TEAM_x\":\"TEAM\"})\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "Current_df = pd.DataFrame(columns = result.columns)\n",
    "Current_df['ALLSTAR'] = None\n",
    "Current_df['TEAM_STANDING'] = None\n",
    "\n",
    "for i,player in result.iterrows():\n",
    "\n",
    "    ################# Adding ALLSTAR Column ##################\n",
    "    if player['NAME'].replace('*','') in allstar_arr:\n",
    "        player['ALLSTAR'] = 1\n",
    "    else:\n",
    "        player['ALLSTAR'] = 0\n",
    "\n",
    "\n",
    "    ################ Adding Team standing column ############\n",
    "\n",
    "    team_abrv = player[\"TEAM\"].replace(' ','')\n",
    "\n",
    "    if team_abrv not in team_names_dict and team_abrv !=  'TOT' :\n",
    "        #print(team_abrv + \" not in dict\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        #if a player played on multiple teams in a year then its tough to take a look at their record so we \n",
    "        #just won't use them because there isn't that many\n",
    "        if team_abrv == 'TOT': \n",
    "\n",
    "            #since the team that a player is on now will likely be 2 rows below current player we take that player\n",
    "            curr_team_player = result.loc[i+2]\n",
    "\n",
    "            #Extracting the team ID\n",
    "\n",
    "            curr_team_id = curr_team_player['TEAM'].replace(' ','')\n",
    "\n",
    "            #this finds the team name for the player\n",
    "            team_name = team_names_dict[curr_team_id]\n",
    "            #Extract the standings for the current team \n",
    "            player['TEAM_STANDING'] = standings[team_name] \n",
    "        else:\n",
    "            #this finds the team name for the player\n",
    "            team_name = team_names_dict[team_abrv]\n",
    "            player['TEAM_STANDING'] = standings[team_name]\n",
    "\n",
    "    except:\n",
    "        #print( team_abrv+ \" ESPN doesn't have them in the standings this year\" )\n",
    "        continue\n",
    "\n",
    "    Current_df = Current_df.append(player,ignore_index=True)\n",
    "\n",
    "    \n",
    "Current_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting dataframe to a csv file \n",
    "out_filename = \"csv_files/Current_Players.csv\"\n",
    "Current_df.to_csv(path_or_buf = out_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
